{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "905354da-1ffc-41c0-86fa-5241396e0a49",
   "metadata": {},
   "source": [
    "# Current_IPOs_GMP_Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf17d27-41f2-42fa-8d14-78ffaae59946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch the webpage\n",
    "url = \"https://www.investorgain.com/report/live-ipo-gmp/331/current/\"\n",
    "response = requests.get(url)\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all tables on the page\n",
    "tables = soup.find_all(\"table\")\n",
    "# Extract data from the first table\n",
    "table_data = []\n",
    "if len(tables) >= 1:\n",
    "    first_table = tables[0]\n",
    "    rows = first_table.find_all(\"tr\")\n",
    "    for row in rows:\n",
    "        cells = row.find_all([\"td\", \"th\"])\n",
    "        row_data = [cell.text.strip() for cell in cells]\n",
    "        if row_data:\n",
    "            table_data.append(row_data)\n",
    "# Convert the data to a pandas DataFrame\n",
    "df = pd.DataFrame(table_data[1:], columns=table_data[0])\n",
    "# Define the file path for exporting to desktop\n",
    "#desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "#file_path = os.path.join(desktop_path, \"Current_IPOs.csv\")\n",
    "# Export DataFrame to CSV\n",
    "#df.to_csv(file_path, index=False)\n",
    "#print(f\"Data exported to {file_path}\")\n",
    "df1 = pd.read_csv(\"desktop/IPO/Current_IPOs.csv\")\n",
    "df.to_csv('desktop/IPO/Current_IPOs.csv', index=False)\n",
    "##Data Cleaning\n",
    "df1.drop(columns=[\"Fire Rating\",\"IPO Size\", \"Est Listing\"], inplace=True)\n",
    "df1.dropna(subset=[\"Price\"], inplace=True)\n",
    "df1.replace(\"--\", 0, inplace=True)\n",
    "df1[\"Lot\"] = pd.to_numeric(df1[\"Lot\"], errors='coerce')\n",
    "df1.rename(columns={\"GMP(â‚¹)\": \"GMP\"}, inplace=True)\n",
    "df1 = df1[df1[\"IPO\"].str.contains('Open|Today', case=False)]\n",
    "df1['IPO_Name'] = df1['IPO'].str.split().str[:2].str.join(' ')\n",
    "df1['IPOfirstname'] = df1['IPO'].str.split().str[0]\n",
    "df1[\"Amount\"] = df1[\"Price\"]* df1[\"Lot\"]\n",
    "df1[\"Profit\"] = df1[\"GMP\"].astype(float) * df1[\"Lot\"]\n",
    "\n",
    "# Create a new field based on \"IPO\" column\n",
    "df1['IPO_Type'] = df1['IPO'].apply(lambda x: 'SME' if 'SME' in x else 'Mainboard')\n",
    "df1.to_csv(r'C:\\Users\\vjha8\\Desktop\\IPO\\cleaned_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e90f19-477b-4322-b003-e0975083da5c",
   "metadata": {},
   "source": [
    "# Mainboad IPOs Subscription Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d1df9b-544e-4dfd-b20f-ac997898bf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mainboard_IPOs_subs_Status downloaded at desktop\n"
     ]
    }
   ],
   "source": [
    "# URL of the webpage\n",
    "url = \"https://www.chittorgarh.com/report/ipo-subscription-status-live-bidding-data-bse-nse/21/\"\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "# Parse HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "# Find the second table on the webpage\n",
    "table = soup.find_all(\"table\")[2]  # Index 1 for the second table\n",
    "# Extract data from the table\n",
    "data = []\n",
    "for row in table.find_all(\"tr\"):\n",
    "    row_data = [cell.get_text(strip=True) for cell in row.find_all([\"th\", \"td\"])]\n",
    "    data.append(row_data)\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data[1:], columns=data[0])\n",
    "if \"Applications\" in df.columns:\n",
    "    df.drop(columns=[\"Applications\"], inplace=True)\n",
    "if \"Size (Rs Cr)\" in df.columns:\n",
    "    df.drop(columns=[\"Size (Rs Cr)\"], inplace=True)\n",
    "if \"Close Date\" in df.columns:\n",
    "    df.drop(columns=[\"Close Date\"], inplace=True)\n",
    "# Export DataFrame to CSV\n",
    "df.to_csv(r'C:\\Users\\vjha8\\Desktop\\IPO\\Mainboard_IPOs_subs_Status.csv', index=False)\n",
    "print(\"Mainboard_IPOs_subs_Status downloaded at desktop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b070afc-ef7e-4f45-b47e-8546e877e52e",
   "metadata": {},
   "source": [
    "# SME IPOs Subscription Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73ad9a72-0be0-401a-9f84-562b81c8b878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SME_IPOs_subs_Status downloaded at desktop\n"
     ]
    }
   ],
   "source": [
    "# URL of the webpage\n",
    "url = \"https://www.chittorgarh.com/report/ipo-subscription-status-live-bidding-data-bse-nse/22/\"\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "# Parse HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "# Find the second table on the webpage\n",
    "table = soup.find_all(\"table\")[2]  # Index 1 for the second table\n",
    "# Extract data from the table\n",
    "data = []\n",
    "for row in table.find_all(\"tr\"):\n",
    "    row_data = [cell.get_text(strip=True) for cell in row.find_all([\"th\", \"td\"])]\n",
    "    data.append(row_data)\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data[1:], columns=data[0])\n",
    "if \"Applications\" in df.columns:\n",
    "    df.drop(columns=[\"Applications\"], inplace=True)\n",
    "if \"Size (Rs Cr)\" in df.columns:\n",
    "    df.drop(columns=[\"Size (Rs Cr)\"], inplace=True)\n",
    "if \"Open Date\" in df.columns:\n",
    "    df.drop(columns=[\"Open Date\"], inplace=True)\n",
    "if \"Close Date\" in df.columns:\n",
    "    df.drop(columns=[\"Close Date\"], inplace=True)\n",
    "# Export DataFrame to CSV\n",
    "df.to_csv(r'C:\\Users\\vjha8\\Desktop\\IPO\\SME_IPOs_subs_Status.csv', index=False)\n",
    "print(\"SME_IPOs_subs_Status downloaded at desktop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d1cbff-4700-4749-81fa-1b93d42306e1",
   "metadata": {},
   "source": [
    "# Final data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f6348e0-d129-4597-8da9-503c4713ad9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finaldata downloaded at desktop\\IPO\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "sme = pd.read_csv('Desktop\\IPO\\SME_IPOs_subs_Status.csv')\n",
    "main = pd.read_csv('Desktop\\IPO\\Mainboard_IPOs_subs_Status.csv')\n",
    "cleaned = pd.read_csv('Desktop\\IPO\\cleaned_df.csv')\n",
    "\n",
    "# Fill null values with 0\n",
    "sme.fillna(0, inplace=True)\n",
    "main.fillna(0, inplace=True)\n",
    "\n",
    "# Clean 'Company Name' column\n",
    "sme['Company Name'] = sme['Company Name'].str.replace('-', ' ')\n",
    "main['Company Name'] = main['Company Name'].str.replace('-', ' ')\n",
    "\n",
    "# Extract 'firstname' from 'Company Name'\n",
    "sme['firstname'] = sme['Company Name'].str.split(n=1).str[0]\n",
    "main['firstname'] = main['Company Name'].str.split(n=1).str[0]\n",
    "\n",
    "# Select only the required columns from 'sme' and 'main'\n",
    "sme_subset = sme[['firstname', 'QIB (x)', 'NII (x)', 'Retail (x)']]\n",
    "main_subset = main[['firstname', 'QIB (x)', 'NII (x)', 'Retail (x)']]\n",
    "\n",
    "# Merge 'cleaned' with 'sme_subset' first\n",
    "merged_df = pd.merge(cleaned, sme_subset, how='left', left_on='IPOfirstname', right_on='firstname')\n",
    "\n",
    "# Merge 'cleaned' with 'main_subset' separately\n",
    "main_merged = pd.merge(cleaned, main_subset, how='left', left_on='IPOfirstname', right_on='firstname')\n",
    "\n",
    "# Combine the results, preferring sme values if available\n",
    "for col in ['QIB (x)', 'NII (x)', 'Retail (x)']:\n",
    "    merged_df[col] = merged_df[col].combine_first(main_merged[col])\n",
    "\n",
    "# Drop the duplicate 'firstname' column from the first merge\n",
    "merged_df.drop(columns=['firstname'], inplace=True)\n",
    "\n",
    "# Save the merged DataFrame to Excel\n",
    "merged_df.to_excel(r'C:\\Users\\vjha8\\Desktop\\IPO\\finaldata.xlsx', index=False)\n",
    "print(\"Finaldata downloaded at desktop\\IPO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b29e8-60af-4e2f-b212-f97612885190",
   "metadata": {},
   "source": [
    "# Importing data on Google Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1e8201a-dccb-4500-bdc6-1efd5c3dadd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully pushed to the Google Sheet.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "# Load data from CSV files\n",
    "sme = pd.read_csv('Desktop/IPO/SME_IPOs_subs_Status.csv')\n",
    "main = pd.read_csv('Desktop/IPO/Mainboard_IPOs_subs_Status.csv')\n",
    "cleaned = pd.read_csv('Desktop/IPO/cleaned_df.csv')\n",
    "\n",
    "# Preprocess data\n",
    "sme['Company Name'] = sme['Company Name'].str.replace('-', ' ')\n",
    "sme['firstname'] = sme['Company Name'].str.split(n=1).str[0]\n",
    "main['Company Name'] = main['Company Name'].str.replace('-', ' ')\n",
    "main['firstname'] = main['Company Name'].str.split(n=1).str[0]\n",
    "\n",
    "sme.fillna(0, inplace=True)\n",
    "main.fillna(0, inplace=True)\n",
    "\n",
    "# Selecting only the required columns from 'sme' and 'main'\n",
    "sme_subset = sme[['QIB (x)','NII (x)','Retail (x)','Total (x)','firstname']]\n",
    "main_subset = main[['QIB (x)','NII (x)','Retail (x)','Total (x)','firstname']]\n",
    "\n",
    "\n",
    "merged_df = pd.merge(cleaned, sme_subset, how='left', left_on='IPOfirstname', right_on='firstname')\n",
    "merged_df.fillna(0, inplace=True)\n",
    "# Merging 'cleaned' with 'main_subset' separately\n",
    "main_merged = pd.merge(cleaned, main_subset, how='left', left_on='IPOfirstname', right_on='firstname')\n",
    "\n",
    "\n",
    "# Combine the results, preferring sme values if available\n",
    "for col in ['QIB (x)', 'NII (x)', 'Retail (x)']:\n",
    "    if col in merged_df.columns and col in main_merged.columns:\n",
    "        merged_df[col] = merged_df[col].combine_first(main_merged[col])\n",
    "merged_df.drop(columns=['firstname'], inplace=True)\n",
    "\n",
    "# Authenticate with Google Sheets API\n",
    "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(r'C:\\Users\\vjha8\\Downloads\\authfile.json', scope)\n",
    "client = gspread.authorize(credentials)\n",
    "\n",
    "# Open the specific spreadsheet by its title\n",
    "spreadsheet = client.open('IPO')\n",
    "\n",
    "# Select the worksheet where you want to update the data\n",
    "worksheet = spreadsheet.get_worksheet(0)  # Replace 0 with the index of your worksheet\n",
    "\n",
    "# Clear existing data from the worksheet\n",
    "worksheet.clear()\n",
    "\n",
    "# Convert DataFrame to a list of lists (2D array) for easy upload\n",
    "data = [merged_df.columns.tolist()] + merged_df.values.tolist()\n",
    "\n",
    "# Append data to the worksheet\n",
    "worksheet.append_rows(data)\n",
    "\n",
    "print(\"Data has been successfully pushed to the Google Sheet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d77081-b257-4b5a-875f-136e8ecc75cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
